{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "#Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Save model\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileLocation = 'C:\\\\Users\\\\VictorY\\\\Desktop\\\\TestData\\\\stage3FinalProcessedDF_Nov-17-2019.csv'\n",
    "# moviesDataFileLocation = 'C:\\\\Yuva\\\\ITU\\\\4th Sem\\\\Thesis\\\\Data\\\\Final_Data_Movies_Directors_old.csv'\n",
    "# moviesDataFileLocation = 'C:\\\\Yuva\\\\ITU\\\\4th Sem\\\\Thesis\\\\Data\\\\Final_data_movies_director.csv'\n",
    "# moviesDataFileLocation = 'C:\\\\Yuva\\\\ITU\\\\4th Sem\\\\Thesis\\\\Data\\\\Movies_Directors_WithAwards.csv'\n",
    "\n",
    "#Dynamic path location\n",
    "# moviesDataFileLocation = os.path.join(os.path.realpath(os.path.pardir),'datasets\\\\data1_Data_Movies.csv')\n",
    "# moviesDataFileLocation = os.path.join(os.path.realpath(os.path.pardir),'datasets\\\\data2_Movies_WithAwards.csv')\n",
    "\n",
    "fileName = '1_Director_Data_Mar-21-2020'\n",
    "DataFileLocation = os.path.join(os.path.realpath(os.path.pardir),'datasets\\\\'+ fileName +'.csv')\n",
    "\n",
    "\n",
    "saveFileToPath = \"C:\\\\Yuva\\\\ITU\\\\4th Sem\\\\Thesis\\\\Data\\\\\"\n",
    "\n",
    "movies_data = pd.read_csv(DataFileLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_data = movies_data.sample(n=10000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41629 entries, 0 to 41628\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   director_ids              41629 non-null  object \n",
      " 1   director_name             41629 non-null  object \n",
      " 2   movies_produced           41629 non-null  int64  \n",
      " 3   average_rating_value      41629 non-null  float64\n",
      " 4   average_rating_count      41629 non-null  float64\n",
      " 5   career_Length             41629 non-null  int64  \n",
      " 6   Gender                    41629 non-null  object \n",
      " 7   birthYear                 41629 non-null  int64  \n",
      " 8   primaryProfession         41629 non-null  object \n",
      " 9   knownForTitles            41629 non-null  object \n",
      " 10  CareerStartYear           41629 non-null  int64  \n",
      " 11  median_inter_event_time   41629 non-null  float64\n",
      " 12  average_movie_per_year    41629 non-null  float64\n",
      " 13  average_inter_event_time  41629 non-null  float64\n",
      "dtypes: float64(5), int64(4), object(5)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "movies_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      32638\n",
       "Female     8991\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalGender = {\"Male\": 1, \"Female\": 0 }\n",
    "movies_data.Gender.replace(numericalGender,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['director_ids', 'director_name', 'primaryProfession', 'knownForTitles']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_features_to_remove = movies_data.select_dtypes(include = 'object').columns.values.tolist()\n",
    "# object_features_to_remove.remove('Gender')\n",
    "object_features_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# req_columns = ['review_count_user', 'review_count_critic','rating_value',\n",
    "#                'rating_count','movie_year','birthYear','Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our Unbalanced Movies dataset is: (41629, 10)\n"
     ]
    }
   ],
   "source": [
    "# movies_data = movies_data[req_columns]\n",
    "movies_data = movies_data[movies_data.columns.difference(object_features_to_remove)]\n",
    "# movies_data.drop(columns = ['Gender_Male','Gender_Female'],inplace = True)\n",
    "\n",
    "print('The shape of our Unbalanced Movies dataset is:', movies_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_data = movies_data[req_columns]\n",
    "# print('The shape of our Director specific dataset is:', movies_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "2. SVM Classifier\n",
    "3. Gradient Boost Classifier\n",
    "4. XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartile_bin(df,class_feature='rating_value'):\n",
    "    # Quartile cut into 4 different buckets\n",
    "\n",
    "    bin_quartiles = ['terrible','poor','average','excellent']\n",
    "    cutIntoQuartiles = pd.qcut(df[class_feature].to_list(), q=4,labels=bin_quartiles)\n",
    "    \n",
    "    print(cutIntoQuartiles.categories)\n",
    "    \n",
    "    df['class'] = cutIntoQuartiles\n",
    "    df['class'] = df['class'].astype(object)\n",
    "    print('The shape of our dataset before dropping the class feature is:', df.shape)\n",
    "    df.drop(columns = [class_feature] , inplace = True)\n",
    "    print('The shape of our dataset after dropping the class feature  is:', df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CareerStartYear', 'Gender', 'average_inter_event_time',\n",
       "       'average_movie_per_year', 'average_rating_count',\n",
       "       'average_rating_value', 'birthYear', 'career_Length',\n",
       "       'median_inter_event_time', 'movies_produced'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Feature selection through : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['terrible', 'poor', 'average', 'excellent'], dtype='object')\n",
      "The shape of our dataset before dropping the class feature is: (41629, 11)\n",
      "The shape of our dataset after dropping the class feature  is: (41629, 10)\n"
     ]
    }
   ],
   "source": [
    "df = quartile_bin(movies_data,'average_rating_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CareerStartYear</th>\n",
       "      <th>Gender</th>\n",
       "      <th>average_inter_event_time</th>\n",
       "      <th>average_movie_per_year</th>\n",
       "      <th>average_rating_value</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>career_Length</th>\n",
       "      <th>median_inter_event_time</th>\n",
       "      <th>movies_produced</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.11</td>\n",
       "      <td>7.36</td>\n",
       "      <td>1918</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1925</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1899</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1973</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1916</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41624</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.90</td>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41625</th>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41626</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41627</th>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41628</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41629 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CareerStartYear  Gender  average_inter_event_time  \\\n",
       "0                 1946       1                       0.9   \n",
       "1                 1961       1                       0.0   \n",
       "2                 1967       1                       0.0   \n",
       "3                 1957       1                       0.0   \n",
       "4                 1973       1                       2.0   \n",
       "...                ...     ...                       ...   \n",
       "41624             2015       1                       0.0   \n",
       "41625             2016       0                       0.0   \n",
       "41626             2016       1                       0.0   \n",
       "41627             2016       0                       0.0   \n",
       "41628             2016       1                       0.0   \n",
       "\n",
       "       average_movie_per_year  average_rating_value  birthYear  career_Length  \\\n",
       "0                        1.11                  7.36       1918             63   \n",
       "1                        1.00                  7.20       1924              1   \n",
       "2                        1.00                  5.70       1925              1   \n",
       "3                        1.00                  5.80       1899              1   \n",
       "4                        0.67                  5.85       1916              3   \n",
       "...                       ...                   ...        ...            ...   \n",
       "41624                    1.00                  9.90       1982              1   \n",
       "41625                    1.00                 10.00       1999              1   \n",
       "41626                    1.00                  9.20       1990              1   \n",
       "41627                    1.00                  9.70       1995              1   \n",
       "41628                    1.00                  5.00       1996              1   \n",
       "\n",
       "       median_inter_event_time  movies_produced      class  \n",
       "0                          1.0               70  excellent  \n",
       "1                          0.0                1  excellent  \n",
       "2                          0.0                1  excellent  \n",
       "3                          0.0                1  excellent  \n",
       "4                          2.0                2  excellent  \n",
       "...                        ...              ...        ...  \n",
       "41624                      0.0                1   terrible  \n",
       "41625                      0.0                1   terrible  \n",
       "41626                      0.0                1       poor  \n",
       "41627                      0.0                1   terrible  \n",
       "41628                      0.0                1   terrible  \n",
       "\n",
       "[41629 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movies_data.drop(\"class\", axis='columns')   #Feature Matrix\n",
    "y = movies_data[\"class\"]          #Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CareerStartYear', 'Gender', 'average_inter_event_time',\n",
       "       'average_movie_per_year', 'average_rating_value', 'birthYear',\n",
       "       'career_Length', 'median_inter_event_time', 'movies_produced'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_estimator = LogisticRegression()\n",
    "selector = RFE(logistic_model_estimator, n_features_to_select = None , step = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\yuvar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\yuvar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\yuvar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\yuvar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support :  [False False  True False  True False  True  True False]\n",
      "\n",
      "Ranking :  [5 6 1 2 1 4 1 1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X, y)\n",
    "print(\"Support : \" , selector.support_)\n",
    "print(\"\\nRanking : \" , selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = selector.get_support(1) #the most important features\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_inter_event_time</th>\n",
       "      <th>average_rating_value</th>\n",
       "      <th>career_Length</th>\n",
       "      <th>median_inter_event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>7.36</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.85</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41624</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41625</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41627</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41628</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41629 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       average_inter_event_time  average_rating_value  career_Length  \\\n",
       "0                           0.9                  7.36             63   \n",
       "1                           0.0                  7.20              1   \n",
       "2                           0.0                  5.70              1   \n",
       "3                           0.0                  5.80              1   \n",
       "4                           2.0                  5.85              3   \n",
       "...                         ...                   ...            ...   \n",
       "41624                       0.0                  9.90              1   \n",
       "41625                       0.0                 10.00              1   \n",
       "41626                       0.0                  9.20              1   \n",
       "41627                       0.0                  9.70              1   \n",
       "41628                       0.0                  5.00              1   \n",
       "\n",
       "       median_inter_event_time  \n",
       "0                          1.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          2.0  \n",
       "...                        ...  \n",
       "41624                      0.0  \n",
       "41625                      0.0  \n",
       "41626                      0.0  \n",
       "41627                      0.0  \n",
       "41628                      0.0  \n",
       "\n",
       "[41629 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imporant_features_X_df = X[X.columns[f]] # final features`\n",
    "imporant_features_X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CareerStartYear', 'average_rating_count', 'birthYear',\n",
       "       'career_Length', 'movies_produced'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imporant_features_X_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Feature Selection : SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data_new = movies_data.sample(1000,random_state = 42)\n",
    "movies_data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movies_data_new.drop(\"Gender\", axis='columns')   #Feature Matrix\n",
    "y = movies_data_new[\"Gender\"]          #Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_estimator = SVC(kernel=\"linear\")\n",
    "svc_rfe = RFE(estimator = svc_estimator, n_features_to_select = None , step=1)\n",
    "svc_rfe = svc_rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE parameters\n",
    "svc_rfe.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rfe.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Support : \" , svc_rfe.support_)\n",
    "print(\"Ranking : \" , svc_rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = svc_rfe.get_support(1) #the most important features\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X = X[X.columns[f]]\n",
    "reduced_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature Selection - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting classifiers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_data_new = movies_data.sample(100,random_state = 42)\n",
    "# movies_data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movies_data.drop(\"Gender\", axis='columns')   #Feature Matrix\n",
    "y = movies_data[\"Gender\"]          #Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_estimator = GradientBoostingClassifier(n_estimators=100,\n",
    "                                         learning_rate=0.1,\n",
    "                                         max_leaf_nodes = 32\n",
    "                                         )\n",
    "\n",
    "gb_rfe = RFE(estimator = gb_estimator, n_features_to_select = None , step=1)\n",
    "gb_rfe = gb_rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rfe.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Support : \" , gb_rfe.support_)\n",
    "print(\"Ranking : \" , gb_rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gb_rfe.get_support(1) #the most important features\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X = X[X.columns[f]]\n",
    "reduced_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movies_data.drop(\"Gender\", axis='columns')   #Feature Matrix\n",
    "y = movies_data[\"Gender\"]          #Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = XGBClassifier(n_estimators=100,\n",
    "                        learning_rate=0.1,\n",
    "                        max_features=2,\n",
    "                        max_depth=2,\n",
    "                        random_state= 42\n",
    "                        )\n",
    "\n",
    "xgb_rfe = RFE(estimator = xgb_estimator, n_features_to_select = None , step=1)\n",
    "xgb_rfe = xgb_rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rfe.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Support : \" , xgb_rfe.support_)\n",
    "print(\"Ranking : \" , xgb_rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = xgb_rfe.get_support(1) #the most important features\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X = X[X.columns[f]]\n",
    "reduced_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = movies_data.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"Gender\"])\n",
    "print(cor_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target[cor_target>0.07].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.5]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimum number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data_new = movies_data.sample(1000,random_state = 42)\n",
    "movies_data_new.shape\n",
    "\n",
    "X = movies_data_new.drop(\"Gender\", axis='columns')   #Feature Matrix\n",
    "y = movies_data_new[\"Gender\"]          #Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,len(movies_data.columns))            \n",
    "high_score=0\n",
    "\n",
    "#Variable to store the optimum features\n",
    "nof=0\n",
    "score_list =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "    # Training the model\n",
    "    svclassifier = SVC(kernel='linear')\n",
    "    rfe = RFE(svclassifier,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    svclassifier.fit(X_train_rfe,y_train)\n",
    "    score = svclassifier.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  RFE Cross validation with XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature ranking with recursive feature elimination and cross-validated selection of the best number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_data_new = movies_data.sample(1000,random_state = 42)\n",
    "# movies_data_new.shape\n",
    "\n",
    "X = movies_data.drop(\"Gender\", axis='columns')   #Feature Matrix\n",
    "y = movies_data[\"Gender\"]                        #Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = XGBClassifier(n_estimators=100,\n",
    "                        learning_rate= 0.1,\n",
    "                        max_features=2,\n",
    "                        max_depth=2,\n",
    "                        random_state= 42\n",
    "                        )\n",
    "\n",
    "xgb_rfe = RFECV(estimator = xgb_estimator, min_features_to_select = 10 , step=1 , cv = 5 )\n",
    "xgb_rfe = xgb_rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = xgb_rfe.get_support(1) #the most important features\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X = X[X.columns[f]]\n",
    "reduced_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_XGB_classifier(X_train, X_test, y_train, y_test,learning_rate = 1):\n",
    "    \n",
    "    # Classifier parameters    \n",
    "\n",
    "    xgb_clf = XGBClassifier(n_estimators=100,\n",
    "                            learning_rate=learning_rate,\n",
    "                            max_features=2,\n",
    "                            max_depth=2,\n",
    "                            random_state= 42\n",
    "                           )\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "    \n",
    "    xgb_train_score = xgb_clf.score(X_train, y_train)\n",
    "    print(\"Training Score : \",round(xgb_train_score,3))\n",
    "    \n",
    "    xgb_test_score = xgb_clf.score(X_test, y_test)\n",
    "    print(\"Testing Score : \",round(xgb_test_score,3))\n",
    "    \n",
    "    predictions = xgb_clf.predict(X_test)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    return xgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_test_train_with_scaling_methods(df,predict='Gender',scalingMethod = \"MinMaxScaler\"):\n",
    "    \n",
    "    \n",
    "    # Feature matrix and target variable\n",
    "    X = df.drop(predict,axis = 'columns')\n",
    "    y = df[predict]\n",
    "    \n",
    "    # Scaling\n",
    "    if (scalingMethod == \"MinMaxScaler\"):\n",
    "        print(\"The scaling method used is : \",scalingMethod)\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X)\n",
    "        # X_test = scaler.transform(X_test)\n",
    "        \n",
    "    else:\n",
    "        print(\"No Scaling Method used or incorrect input\")\n",
    "        X_train = X\n",
    "    \n",
    "    # Divide the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size =0.20, random_state = 42 )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_columns = ['rating_value', 'rating_count', 'movie_year', 'birthYear','Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies_data.select_dtypes(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data = movies_data[req_columns]\n",
    "print('The shape of our Director specific dataset is:', movies_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = divide_test_train_with_scaling_methods(movies_data,scalingMethod=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_XGB_classifier(X_train, X_test, y_train, y_test,learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
